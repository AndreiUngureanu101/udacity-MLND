{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# Import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "%matplotlib qt\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "from mne import pick_types, Annotations, create_info, find_events, Epochs\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import RawArray\n",
    "from mne.epochs import concatenate_epochs\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from scipy.signal import welch\n",
    "from mne.viz.topomap import _prepare_topo_plot, plot_topomap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a neural network\n",
    "\n",
    "###### We'll use series 1 through 6 for training and series 7 and 8 for validating the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data file names for a all subject, series 1 through 8 for normalization\n",
    "series = list(range(1,9))\n",
    "file = f'grasp-and-lift-eeg-detection/train/subj*_series{series}_data.csv'\n",
    "dirpath = os.path.join(os.getcwd(),file)\n",
    "glob_object = glob.glob(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the data and calculate the mean and standard deviation for each channel\n",
    "data_all = np.empty((32,0))\n",
    "for file in glob_object:\n",
    "    data_df = pd.read_csv(file).drop(['id'], axis=1)\n",
    "    data_np = data_df.to_numpy().transpose()\n",
    "    data_all = np.concatenate((data_all,data_np),axis=1)\n",
    "MEAN = data_all.mean(1).reshape(32,1)\n",
    "ST_DEV = data_all.std(1).reshape(32,1)\n",
    "maximum = np.amax(data_all, axis = 1).reshape(32,1)\n",
    "minimum = np.amin(data_all, axis = 1).reshape(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(MEAN, open(\"MEAN.pkl\", \"wb\"))\n",
    "pkl.dump(ST_DEV, open(\"ST_DEV.pkl\", \"wb\"))\n",
    "pkl.dump(maximum, open(\"maximum.pkl\", \"wb\"))\n",
    "pkl.dump(minimum, open(\"minimum.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = pkl.load( open( \"MEAN.pkl\", \"rb\" ) )\n",
    "ST_DEV = pkl.load( open( \"ST_DEV.pkl\", \"rb\" ) )\n",
    "maximum = pkl.load( open( \"maximum.pkl\", \"rb\" ) )\n",
    "minimum = pkl.load( open( \"minimum.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data file names for a all subject, series 1 through 6 for generating the training data\n",
    "series = list(range(1,7))\n",
    "file = f'grasp-and-lift-eeg-detection/train/subj*_series{series}_data.csv'\n",
    "dirpath = os.path.join(os.getcwd(),file)\n",
    "glob_object = glob.glob(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "win_length = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(data,events,batch_size,win_length):\n",
    "    batches = data.shape[1]//(win_length*batch_size)  \n",
    "    \n",
    "    data_out = np.empty((batches,batch_size,32,win_length))\n",
    "    events_out = np.empty((batches,batch_size,6))\n",
    "    \n",
    "    data_temp = np.empty((batch_size,32,win_length))\n",
    "    events_temp = np.empty((batch_size,6))\n",
    "    \n",
    "    batch_length = batch_size*win_length\n",
    "    \n",
    "    for k in range(batches):\n",
    "        for i in range(batch_size):\n",
    "            data_temp[i,:,:] = data[:,(k*batch_length)+(i*win_length):(k*batch_length)+(i+1)*win_length]\n",
    "            events_temp[i] = events[:,(k*batch_length)+(i+1)*win_length-1]\n",
    "        data_out[k,:,:,:] = data_temp\n",
    "        events_out[k,:,:] = events_temp\n",
    "    return (data_out, events_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(glob_object):\n",
    "    \n",
    "    X = np.empty((0,batch_size,32,win_length))\n",
    "    Y = np.empty((0,batch_size,6))\n",
    "\n",
    "    for file in glob_object:\n",
    "\n",
    "        data_df = pd.read_csv(file).drop(['id'], axis=1)\n",
    "        data_np = data_df.to_numpy().transpose()\n",
    "        # threshold data so it can fit in batches\n",
    "        thresh = data_np.shape[1] - (data_np.shape[1] % (batch_size*win_length))\n",
    "        data_np = data_np[:,:thresh]\n",
    "        #normalize the data\n",
    "        data_np = data_np - minimum\n",
    "        data_np = data_np  / (maximum - minimum)     \n",
    "        file = file.replace('data','events')\n",
    "        events_df = pd.read_csv(file).drop(['id'], axis=1)\n",
    "        events_np = events_df.to_numpy().transpose()\n",
    "        events_np = events_np[:,:thresh]   \n",
    "\n",
    "        data, events = reshape_data(data_np,events_np,batch_size,win_length)\n",
    "\n",
    "        X = np.concatenate((X,data),axis=0)\n",
    "        Y = np.concatenate((Y,events),axis=0)\n",
    "\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = generate_data(glob_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3046, 32, 32, 150)\n",
      "(3046, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(X_train[:,:,:,:]))\n",
    "print(np.amin(X_train[:,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(X_train, open(\"X_train.pkl\", \"wb\"))\n",
    "pkl.dump(Y_train, open(\"Y_train.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pkl.load( open( \"X_train.pkl\", \"rb\" ) )\n",
    "Y_train = pkl.load( open( \"Y_train.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data file names for a all subject, series 7 and 8 for building the validation data\n",
    "series = [7,8]\n",
    "file = f'grasp-and-lift-eeg-detection/train/subj*_series{series}_data.csv'\n",
    "dirpath = os.path.join(os.getcwd(),file)\n",
    "glob_object = glob.glob(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, Y_valid = generate_data(glob_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(646, 32, 32, 150)\n",
      "(646, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(X_valid[:,:,:,:]))\n",
    "print(np.amin(X_valid[:,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(X_valid, open(\"X_valid.pkl\", \"wb\"))\n",
    "pkl.dump(Y_valid, open(\"Y_valid.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pkl.load( open( \"X_valid.pkl\", \"rb\" ) )\n",
    "Y_valid = pkl.load( open( \"Y_valid.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_result(arr, batch_size):\n",
    "    return torch.where(arr > 0.2, torch.ones(batch_size,6), torch.zeros(batch_size,6)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(model,X,Y):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for i in range(X.shape[0]):\n",
    "        y_hat = model(torch.tensor(X[i,:,:,:]))\n",
    "        y_hat = binarize_result(y_hat,batch_size)\n",
    "        y = Y[i,:,:]\n",
    "        for j in range(batch_size):\n",
    "            if (sum(y[j]) != 0):\n",
    "                total += 1\n",
    "            if (sum(y[j]) == 0 and sum(y_hat[j]) != 0 ):\n",
    "                fp += 1\n",
    "            if (sum(y[j]) != 0 and np.array_equal(y[j],y_hat[j])):\n",
    "                tp += 1   \n",
    "    print(\" tp:\", tp, \" fp:\", fp)\n",
    "    if (tp+fp) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return tp/(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_valid_loss(model,X,Y):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for i in range(X.shape[0]):\n",
    "        y_hat = model(torch.tensor(X[i,:,:,:])).detach().numpy()\n",
    "        y = Y[i,:,:] \n",
    "        total_loss += log_loss(y,y_hat)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1070\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneDimensionalConvolution(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size):\n",
    "        super(OneDimensionalConvolution, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.c1 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1)\n",
    "        self.c2 = nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, stride=1)\n",
    "        self.m1 = nn.MaxPool1d(3, stride=2)     \n",
    "        \n",
    "        self.c3 = nn.Conv1d(in_channels=8, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.c4 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1) \n",
    "        self.m2 = nn.MaxPool1d(3, stride=2)   \n",
    "        \n",
    "        self.c5 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.c6 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1) \n",
    "        self.m3 = nn.MaxPool1d(3, stride=2)           \n",
    "        \n",
    "        self.c7 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.c8 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1) \n",
    "        self.m4 = nn.MaxPool1d(3, stride=2)    \n",
    "               \n",
    "        self.d1 = nn.Dropout(p=0.1)     \n",
    "        self.l1 = nn.Linear(128,64)\n",
    "        \n",
    "        self.d2 = nn.Dropout(p=0.1)\n",
    "        self.l2 = nn.Linear(64,64)\n",
    "        \n",
    "        self.l3 = nn.Linear(64,6)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.m1(self.c2(self.c1(x))) \n",
    "        x = self.m2(self.c4(self.c3(x)))\n",
    "        x = self.m3(self.c6(self.c5(x)))     \n",
    "        x = self.m4(self.c8(self.c7(x)))\n",
    "        \n",
    "        x = self.d1(x)\n",
    "        x = x.reshape(self.batch_size,-1)\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.d2(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.l3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneDimensionalConvolution(batch_size).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, running loss: 330.8370005353484, validation loss: 269.48424190304326\n",
      "epoch: 1, running loss: 330.4646610085767, validation loss: 269.48311995448404\n",
      "epoch: 2, running loss: 330.710903397521, validation loss: 269.4824818592175\n",
      "epoch: 3, running loss: 330.76603404552867, validation loss: 269.48164498390736\n",
      "epoch: 4, running loss: 330.6543751529954, validation loss: 269.4812012527968\n",
      "epoch: 5, running loss: 330.5838053415779, validation loss: 269.480296991482\n",
      "epoch: 6, running loss: 330.4593879159964, validation loss: 269.47982792301906\n",
      "epoch: 7, running loss: 330.4431805613584, validation loss: 269.47944724915965\n",
      "epoch: 8, running loss: 330.4432558034193, validation loss: 269.4790275735551\n",
      "epoch: 9, running loss: 330.61049163700477, validation loss: 269.4787642934822\n",
      "epoch: 10, running loss: 330.43215315898175, validation loss: 269.47838695993386\n",
      "epoch: 11, running loss: 330.2889846912506, validation loss: 269.4777754105493\n",
      "epoch: 12, running loss: 330.4215937184031, validation loss: 269.47755313077465\n",
      "epoch: 13, running loss: 330.2535511612515, validation loss: 269.4770390672104\n",
      "epoch: 14, running loss: 330.29985415949466, validation loss: 269.4764695086165\n",
      "epoch: 15, running loss: 330.2828580472069, validation loss: 269.4761928248198\n",
      "epoch: 16, running loss: 330.26988819930847, validation loss: 269.4761496965282\n",
      "epoch: 17, running loss: 330.16192741448043, validation loss: 269.47551196695275\n",
      "epoch: 18, running loss: 330.1900499891968, validation loss: 269.4747776315305\n",
      "epoch: 19, running loss: 330.09167752112893, validation loss: 269.4742864683383\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "no_batches = X_train.shape[0]\n",
    "\n",
    "for epoch in range(20):   \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for k in range(no_batches):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        y = model(torch.tensor(X_train[k,:,:,:],requires_grad=True))\n",
    "        y_hat = torch.tensor(Y_train[k,:,:])\n",
    "        loss = criterion(y, y_hat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'epoch: {epoch}, running loss: {running_loss}, validation loss: {calculate_valid_loss(model,X_valid,Y_valid)}')\n",
    "    #print(calculate_precision(model,X_valid,Y_valid))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################################################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = os.path.join(os.getcwd(),'model_SGD_minmax_32')\n",
    "torch.save(model.state_dict(), dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OneDimensionalConvolution(batch_size).double()\n",
    "model.load_state_dict(torch.load(os.path.join(os.getcwd(),'model_SGD_minmax_32_1')))\n",
    "#model.eval()\n",
    "#calculate_precision(model, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneDimensionalConvolution(\n",
       "  (c1): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
       "  (c2): Conv1d(16, 8, kernel_size=(3,), stride=(1,))\n",
       "  (m1): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c3): Conv1d(8, 32, kernel_size=(3,), stride=(1,))\n",
       "  (c4): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
       "  (m2): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c5): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "  (c6): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
       "  (m3): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c7): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  (c8): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
       "  (m4): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (d1): Dropout(p=0.1, inplace=False)\n",
       "  (l1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (d2): Dropout(p=0.1, inplace=False)\n",
       "  (l2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (l3): Linear(in_features=64, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj1_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj1_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj2_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj2_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj3_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj3_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj4_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj4_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj5_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj5_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj6_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj6_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj7_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj7_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj8_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj8_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj9_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj9_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj10_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj10_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj11_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj11_series10_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj12_series9_data.csv\n",
      "/home/cinetic-vr/EEG/grasp-and-lift-eeg-detection/test/subj12_series10_data.csv\n"
     ]
    }
   ],
   "source": [
    "# get the test data and arrange the data to have the same order as in the submission file\n",
    "file = f'grasp-and-lift-eeg-detection/test/subj*_series9_data.csv'\n",
    "dirpath = os.path.join(os.getcwd(),file)\n",
    "glob_object1 = glob.glob(dirpath)\n",
    "\n",
    "file = f'grasp-and-lift-eeg-detection/test/subj*_series10_data.csv'\n",
    "dirpath = os.path.join(os.getcwd(),file)\n",
    "glob_object2 = glob.glob(dirpath)\n",
    "\n",
    "glob_object1.sort()\n",
    "glob_object2.sort()\n",
    "\n",
    "glob_object1 = glob_object1[3:]+glob_object1[:3]\n",
    "glob_object2 = glob_object2[3:]+glob_object2[:3]\n",
    "\n",
    "glob_object = []\n",
    "\n",
    "for i in range(12):\n",
    "    glob_object.append(glob_object1[i])\n",
    "    glob_object.append(glob_object2[i])\n",
    "    \n",
    "for f in glob_object:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_test_data(data,batch_size,win_length):\n",
    "    batches = data.shape[1]//(win_length*batch_size)  \n",
    "    \n",
    "    data_out = np.empty((batches,batch_size,32,win_length))   \n",
    "    data_temp = np.empty((batch_size,32,win_length))\n",
    "    batch_length = batch_size*win_length\n",
    "    \n",
    "    for k in range(batches):\n",
    "        for i in range(batch_size):\n",
    "            data_temp[i,:,:] = data[:,(k*batch_length)+(i*win_length):(k*batch_length)+(i+1)*win_length]\n",
    "        data_out[k,:,:,:] = data_temp\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.empty((0,batch_size,32,win_length))\n",
    "\n",
    "for file in glob_object:\n",
    "\n",
    "    data_df = pd.read_csv(file).drop(['id'], axis=1)\n",
    "    data_np = data_df.to_numpy().transpose()\n",
    "    # threshold data so it can fit in batches\n",
    "    thresh = data_np.shape[1] - (data_np.shape[1] % (batch_size*win_length))\n",
    "    data_np = data_np[:,:thresh]\n",
    "    #normalize the data\n",
    "    data_np = (data_np - minimum) / (maximum - minimum)\n",
    "    data = reshape_test_data(data_np,batch_size,win_length)\n",
    "\n",
    "    X_test = np.concatenate((X_test,data),axis=0)\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 32, 32, 150)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(X_test, open(\"X_test.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
